{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "921f87db72de894fea483ac7c676c060808816f7ff559f43a15893fefaf8b477"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Cleaning and parsing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import re\n",
    "import string\n",
    "import unidecode\n",
    "import contractions\n",
    "import collections\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import functions_text_preprocessing as ftp\n",
    "import functions_text_requesting as ftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====================================================================================================\n",
      "Getting data for: 2021-03-11\n",
      "====================================================================================================\n",
      "Data request started\n",
      "====================================================================================================\n",
      "C:\\Users\\volo\\Anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "C:\\Users\\volo\\Anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n",
      "====================================================================================================\n",
      "Data request finished\n",
      "====================================================================================================\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        TIMESTAMP   STOCK                                              TITLE  \\\n",
       "0    1.615559e+09   $VIVE                               Thoughts on $VIVE? ü§î   \n",
       "1    1.615559e+09   $SLGG                                              $slgg   \n",
       "2    1.615559e+09   $RBLX  Roblox Expanding in China and Asia, the larges...   \n",
       "3    1.615558e+09   $RIDE                     $RIDE'n Dirty, says Hindenberg   \n",
       "4    1.615558e+09   $FRSX  If $FRSX break $10 AH today, it will be over $...   \n",
       "..            ...     ...                                                ...   \n",
       "630  1.615414e+09    $GME  Refueled ‚õΩÔ∏è üöÄ on the Big Dipper now let‚Äôs go t...   \n",
       "631  1.615414e+09   $SURG  SurgePays $SURG, Deloitte TOP 500 Fastest grow...   \n",
       "632  1.615414e+09   $SURG  SurgePays $SURG, Deloitte TOP 500 Fastest grow...   \n",
       "633  1.615414e+09  $MEMES  Trying to post this again, I'm just trying to ...   \n",
       "634  1.615414e+09   $SURG  SurgePays $SURG, Deloitte TOP 500 Fastest grow...   \n",
       "\n",
       "                                                   URL  \n",
       "0    https://www.reddit.com/r/wallstreetbets/commen...  \n",
       "1    https://www.reddit.com/r/wallstreetbets/commen...  \n",
       "2                  https://i.redd.it/980yewn46mm61.jpg  \n",
       "3    https://www.reddit.com/r/wallstreetbets/commen...  \n",
       "4    https://www.reddit.com/r/wallstreetbets/commen...  \n",
       "..                                                 ...  \n",
       "630                https://i.redd.it/mlirh0oz8am61.jpg  \n",
       "631  https://www.reddit.com/r/wallstreetbets/commen...  \n",
       "632  https://www.reddit.com/r/wallstreetbets/commen...  \n",
       "633                https://i.redd.it/zfae9v427am61.png  \n",
       "634  https://www.reddit.com/r/wallstreetbets/commen...  \n",
       "\n",
       "[635 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TIMESTAMP</th>\n      <th>STOCK</th>\n      <th>TITLE</th>\n      <th>URL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.615559e+09</td>\n      <td>$VIVE</td>\n      <td>Thoughts on $VIVE? ü§î</td>\n      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.615559e+09</td>\n      <td>$SLGG</td>\n      <td>$slgg</td>\n      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.615559e+09</td>\n      <td>$RBLX</td>\n      <td>Roblox Expanding in China and Asia, the larges...</td>\n      <td>https://i.redd.it/980yewn46mm61.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.615558e+09</td>\n      <td>$RIDE</td>\n      <td>$RIDE'n Dirty, says Hindenberg</td>\n      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.615558e+09</td>\n      <td>$FRSX</td>\n      <td>If $FRSX break $10 AH today, it will be over $...</td>\n      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>630</th>\n      <td>1.615414e+09</td>\n      <td>$GME</td>\n      <td>Refueled ‚õΩÔ∏è üöÄ on the Big Dipper now let‚Äôs go t...</td>\n      <td>https://i.redd.it/mlirh0oz8am61.jpg</td>\n    </tr>\n    <tr>\n      <th>631</th>\n      <td>1.615414e+09</td>\n      <td>$SURG</td>\n      <td>SurgePays $SURG, Deloitte TOP 500 Fastest grow...</td>\n      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n    </tr>\n    <tr>\n      <th>632</th>\n      <td>1.615414e+09</td>\n      <td>$SURG</td>\n      <td>SurgePays $SURG, Deloitte TOP 500 Fastest grow...</td>\n      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n    </tr>\n    <tr>\n      <th>633</th>\n      <td>1.615414e+09</td>\n      <td>$MEMES</td>\n      <td>Trying to post this again, I'm just trying to ...</td>\n      <td>https://i.redd.it/zfae9v427am61.png</td>\n    </tr>\n    <tr>\n      <th>634</th>\n      <td>1.615414e+09</td>\n      <td>$SURG</td>\n      <td>SurgePays $SURG, Deloitte TOP 500 Fastest grow...</td>\n      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n    </tr>\n  </tbody>\n</table>\n<p>635 rows √ó 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "print(\"=\"*100)\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "yesterday = today - datetime.timedelta(days = 1)\n",
    "\n",
    "data_from = yesterday.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Getting data for: {data_from}\")\n",
    "\n",
    "df = ftr.collect_data(\n",
    "    \n",
    "    day_ = yesterday.day, \n",
    "    \n",
    "    month_ = yesterday.month, \n",
    "    \n",
    "    year_ = yesterday.year, \n",
    "    \n",
    "    verbose = False, \n",
    "    \n",
    "    writefile = False\n",
    "    \n",
    "    )\n",
    "\n",
    "df = ftp.text_preprocessing(\n",
    "    \n",
    "    df = df, \n",
    "    \n",
    "    column_name = \"TITLE\", \n",
    "    \n",
    "    remove_linebreak_pattern = True,\n",
    "\t\n",
    "\tto_lower_case = False,\n",
    "\n",
    "\texpand_contraction_pattern = True,\n",
    "\n",
    "\tremove_emoji_pattern = True,\n",
    "\n",
    "\tremove_punctuation_pattern = False\n",
    "\t\n",
    "\t)\n",
    "\n",
    "df.insert(0, \"id\", range(1, len(df) + 1))\n",
    "\n",
    "df = ftp.extract_content_words(\n",
    "    \n",
    "    df = df, \n",
    "    \n",
    "    part_of_speech = [\"NOUN\",\"VERB\",\"ADJ\",\"AUX\",\"ADV\"], \n",
    "    \n",
    "    save_to_csv = True, \n",
    "    \n",
    "    csv_name = \"data\" + \"-\" + data_from + \".csv\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pos = df_features.groupby([\"pos\"]).size().to_frame(name=\"freq\").reset_index().sort_values(by = \"freq\", ascending = False)\n",
    "# df_pos.reset_index(drop=True, inplace=True)\n",
    "# print(df_pos.pos.unique().tolist())\n",
    "# print(df_pos)\n",
    "\n",
    "# df_freq = df_features[(df_features.pos == \"VERB\") & (df_features.is_alpha == True)]\n",
    "# df_freq = df_freq.groupby([\"lemma\"]).size().to_frame(name=\"freq\").reset_index().sort_values(by = \"freq\", ascending = False)\n",
    "# df_freq.reset_index(drop=True, inplace=True)\n",
    "# print(df_freq)"
   ]
  }
 ]
}